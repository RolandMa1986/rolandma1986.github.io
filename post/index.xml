<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Roland&#39;s Blog</title>
    <link>/post/</link>
    <description>Recent content in Posts on Roland&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>This site is licensed under a [Creative Commons Attribution 4.0 International license](https://creativecommons.org/licenses/by-sa/4.0/).</copyright>
    <lastBuildDate>Sat, 12 Nov 2022 14:15:42 +0000</lastBuildDate><atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>eGalax Touch USB 触摸屏驱动触摸事件优化</title>
      <link>/post/touchscreen/</link>
      <pubDate>Sat, 12 Nov 2022 14:15:42 +0000</pubDate>
      
      <guid>/post/touchscreen/</guid>
      <description>&lt;p&gt;最近在做的工控触摸屏项目，在硬件上使用到了 eGalax Touch 电阻触摸屏。该触屏的驱动支持常见 Linux 发行版，包括 Ubuntu Debian SuSE 等等。在软件层采了用基于 Electron 的客户端开发模式，运行在 Ubuntu 系统上。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NeuVector 会是下一个爆款云原生安全神器吗</title>
      <link>/post/neuvector/</link>
      <pubDate>Mon, 24 Jan 2022 11:15:42 +0000</pubDate>
      
      <guid>/post/neuvector/</guid>
      <description>&lt;p&gt;近日一则《SUSE发布NeuVector：业内首个开源容器安全平台》的文章被转载于各大IT新闻网站。作为 SUSE 家族的新进成员，在3个月后便履行了开源承诺，着实让人赞叹。那么 NeuVector 究竟有哪些过人之处能得到 SUSE 的青睐？而对比各安全厂商的开源安全产品又有哪些突破？接下来，我会以一个 SecDevOps 的视角对 NeuVector 进行简要分析。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kubernetes 运维必知的内核参数和优化项</title>
      <link>/post/sysctl-kubernetes/</link>
      <pubDate>Mon, 17 Jan 2022 14:15:42 +0000</pubDate>
      
      <guid>/post/sysctl-kubernetes/</guid>
      <description>&lt;p&gt;在 Kubernetes 安装过程中，除必要的内核参数外，Kubernetes 并未提供更多的优化建议。但无论 CentOS 或 Ubuntu 默认内核参数通常并不能满足高负载环境下的性能要求。因此，我们需要调整内核参数以优化节点的性能，并使节点更加稳定与健壮。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kubernetes webhook 本地调试方法</title>
      <link>/post/kubernetes-webhook-debug-locally/</link>
      <pubDate>Mon, 06 Dec 2021 01:13:57 +0000</pubDate>
      
      <guid>/post/kubernetes-webhook-debug-locally/</guid>
      <description>在 Kubernetes Webhook 开发过程中，调试是复杂场景下不可或缺的步骤。 但 Kubebuilder 文档中只给出了的远程部署运行步骤以及禁用 webhook 的方法，并没有给出本地调试的具体方法，只是了了数字带过：
If you want to run the webhooks locally, you’ll have to generate certificates for serving the webhooks, and place them in the right directory (/tmp/k8s-webhook-server/serving-certs/tls.{crt,key}, by default).
If you’re not running a local API server, you’ll also need to figure out how to proxy traffic from the remote cluster to your local webhook server.</description>
    </item>
    
    <item>
      <title>深入浅出 Kubernetes 项目网关与应用路由</title>
      <link>/post/kubesphere-routing/</link>
      <pubDate>Fri, 19 Nov 2021 13:23:25 +0000</pubDate>
      
      <guid>/post/kubesphere-routing/</guid>
      <description>&lt;p&gt;KubeSphere 项目网关与应用路由提供了一种聚合服务的方式，将集群的内部服务通过一个外部可访问的 IP 地址以 HTTP 或 HTTPs 暴露给集群外部。应用路由定义了这些服务的访问规则，用户可以定义基于 host 主机名称和 URL 匹配的规则。同时还可以配置 HTTPs offloading 等选项。项目网关则是应用路由的具体实现，它承载了流量的入口并根据应用路由规则将匹配到的请求转发至集群内的服务。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Helm Tips</title>
      <link>/post/helm-tips/</link>
      <pubDate>Mon, 24 May 2021 06:52:16 +0000</pubDate>
      
      <guid>/post/helm-tips/</guid>
      <description>Helm 是最常用的 Kubernetes 包管理器之一。但实际应使用时却会面对各种复杂的问题，以下内容是对常见应用场景的简要总结：
将 kubectl 部署的资源转为 Helm 资源 如果您的项目最初不是使用 Helm 进行资源管理且已经部署在线上运行，那么你可能需要将已有资源转换 Helm 资源。 否则直接运行 helm install 这时你将看见如下错误信息：
Error: rendered manifests contain a resource that already exists. Unable to continue with install: 解决这个问题的方法很简单，只需要将对应的资源打上 Helm 的 Label 和 Annotation 即可:
KIND=deployment NAME=my-app-staging RELEASE=staging NAMESPACE=default kubectl annotate $KIND $NAME meta.helm.sh/release-name=$RELEASE kubectl annotate $KIND $NAME meta.</description>
    </item>
    
    <item>
      <title>Kubernetes CNI 插件性能测试</title>
      <link>/post/kubernetes-cni-performance/</link>
      <pubDate>Wed, 07 Apr 2021 01:13:57 +0000</pubDate>
      
      <guid>/post/kubernetes-cni-performance/</guid>
      <description>网络性能是影响 Kubernetes 集群与应用性能的重要指标之一。同时网络架构也是 Kubernetes 中较为复杂模块之一，Kubernetes 通过开放 CNI 接口，实现了网络插件即插即用功能，CNI 插件的实现方式是影响网络性能的最主要因素。目前主流的 CNI 插件包括：Flannel、Calico、Weave、Canal 和 Cilium 等。除 CNI 插件外，Kube-proxy 运行模式也是影响网络性能的重要因素之一。 Kubernetes 通过 Kube-proxy 提供了集群内负载均衡的能力，其内置方式有 Iptables 和 IPVS 等两种。在不同的场景下，CNI 和 Kube-proxy 都会对网络性能产生显著的影响。本文着重对 Kubernetes 网络性能测试的方法以及影响因素进行讲解和分析，不包含具体插件的性能比较。
Kubernetes 网络通讯模式 在 Kubernetes 网络中，主要有以下几种通讯场景：
容器与容器之间的直接通信，通过本地回环实现，不通过网络插件协议栈，因此测试可以忽略。 Pod与Pod之间的通信，这是测试中的重点，同等条件(物理网卡带宽、CPU等)下性能主要受 CNI 插件影响。 Pod到Service之间的通信，会受到 CNI 与 Kube-proxy 的共同影响，因此也是测试的重点之一。 集群外部与内部组件之间的通信。集群外部访问的模式较多，链路较长，本文不做重点介绍。 除以上场景外，还需要考虑 POD 之间通讯是在同 NODE 与不同 NODE 等两种情况。如果再加上网络协议类型，那么我们需要考虑：通讯场景、协议、跨主机等三个维度的组合。以最常见的模式，我们可以得到以下8种组合：</description>
    </item>
    
    <item>
      <title>Kubernetes 源码调试</title>
      <link>/post/kubernetes-debug-kubernetes-source-code/</link>
      <pubDate>Sun, 17 Jan 2021 12:41:52 +0000</pubDate>
      
      <guid>/post/kubernetes-debug-kubernetes-source-code/</guid>
      <description>前言 本文提供了一种基于 vscode 和 minikube 的快速搭建 Kubernetes 开发调试环境的方法。通过 devle 对 Kubernetes 各个组件进行远程调试。调试代码可以帮助你更深入地理解 Kubernetes 逻辑，更清晰的分析代码执行流程。
准备阶段 Clone kubernetes 源代码 参考官方文档，将 Kubernetes clone 到默认 $GOPATH (Ubuntu 默认路径: ~/go)下 mkdir -p $GOPATH/src/k8s.io cd $GOPATH/src/k8s.io git clone https://github.com/kubernetes/kubernetes cd kubernetes # 以 1.19.x 分支为例我们签出源代码 git checkout release-1.19 # 或签出指定 tag 版本 git checkout v1.19.3 Kubernetes 各个版本的编译对 golang 版本有依赖，例如编译 Kubernetes 1.</description>
    </item>
    
    <item>
      <title>Kiosk 多租户扩展-基本概念</title>
      <link>/post/kubernetes-multi-tenancy-kiosk/</link>
      <pubDate>Wed, 30 Dec 2020 20:46:17 +0800</pubDate>
      
      <guid>/post/kubernetes-multi-tenancy-kiosk/</guid>
      <description>Kubernetes 多租户扩展 使用 Accounts 与 Account User 在共享的 Kubernetes 集群中区分租户 租户自助 Namespace 空间配置 Account Limits 账户配额保障服务质量与公平性 Namespace Templates 命名空间模板保证租户隔离与自助初始化 Namespace。 *多集群租户管理以共享集群池 Why kiosk Kubernetes 被设计为一个单租户平台，因此在单集群上实现多租户功能变得十分困难。然而，共享一个集群有很多优势，例如，资源利用率高，管理配置成本低，也可使租户更容易共享集群内部资源。
当然，创建多租户 Kubernetes 集群的方法有很多，许多 Kubernetes 发行版也提出了他们自己的租户逻辑，然而却没有一个种轻量级的，可热拔插，并可定制化的解决方案。使管理员可以在任何标准的 Kubernetes 集群之上增加多租户能力。
kiosk 愿景 100% 开源：使用 CNCF 兼容的 Apache 2.0 license 即插即用：可轻而易举地在任何已有集群中安装，适用于多种不同的场景 快速：着重于租户的自动化与自助服务 安全：为不同级别的租户隔离提供默认配置 可扩展：providing building blocks for higher-level Kubernetes platforms 架构 kiosk 的核心理念是使用 Kubernetes Namespace 作为隔离的工作空间，租户的应用可以运行在彼此隔离的空间中。为了降低管理成本，集群管理员应该配置 kiosk，然后它将成为一个租户可以在 Kubernetes 中自助配置 Namespace 的系统。</description>
    </item>
    
    <item>
      <title>Kubernetes 层级命名空间 HNC - 3 Why</title>
      <link>/post/kubernetes-multi-tenancy-hnc/</link>
      <pubDate>Mon, 28 Dec 2020 20:34:37 +0800</pubDate>
      
      <guid>/post/kubernetes-multi-tenancy-hnc/</guid>
      <description>为什么使用 namespaces? 在深入讨论层级空间前，我们有必要先考虑一下为何 Kubernetes 使用了命名空间的概念。
首先，也是最重要的，命名空间提供了一种组织 Kubernetes 对象的方式，可以防止同名问题，即集群中的任何 Kind 的实例对象命名必须唯一的问题。对于不同的 Kind 对象命名是可以相同的，但是同一种对象在同一命名空间下是不允许重现重名。对于 Kubernetes 用户，这也有利于用户使用简短的命名，如 frontend 或 database, 而不必担心在集群中产生命名冲突。
其次，重要也很巧妙的设计是，在控制面中命名空间是安全隔离的主要单元和身份标示。他们具有排他性，也就是说，命名空间中的对象属于且仅属于一个命名空间。如上所述，它将对象进行分组。这些分组的独立性使他们可以自然的关联一组相关的对象。 例如，命名空间被作为各种策略的默认目标，如 RoleBinding, Network Policies, 这也适用于 Kubernetes 扩展，如 Istio Polices。
当然，在命名空间内应用策略也是可行的，但是 Kubernetes 对他的支持有限，且容易引起错误，同时在 Kuberenets 生态系统中容易使用户产生困惑。例如，RBAC 策略可以应用于目标对象的名称，但是这些策略很难以维护。
再如，命名空间中的 Pod 可以使用同空间下的任何 Service Account 运行， 甚至是远超过 Pod 运行所需的特权。管理员在不借助 Validting Admission Contoller 或 OPA Gatekeeper 等高级技术情况下，通常无法直接限制。结果是，作用于 Service Account 的各种策略是弱策略，除非这些 Service Account 来自不同的命名空间。</description>
    </item>
    
    <item>
      <title>使用 apt 命令获取 Ubuntu 安装包源码</title>
      <link>/post/how-to-get-source-code-of-package/</link>
      <pubDate>Mon, 14 Dec 2020 15:03:27 +0000</pubDate>
      
      <guid>/post/how-to-get-source-code-of-package/</guid>
      <description>&lt;p&gt;由于最近需要研究一个关于 Ubuntu 上 systemd 的问题，因此需要下载 systemd 的源代码。 一般源码下载可以在官网或者Github中下载，如 systemd。但是由于 linux 各个分发版本可能会给它们打上自己的补丁，因此我们需要从 Ubuntu 下载其源码包。在 Debian 或 Ubuntu 的系统中源码是文件版的软件发行包，因此我们可以使用 apt-get 或者 apt 命令下载其源码 (DEB 文件包)。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kubernetes - &#39;No Podsandbox Found with Id&#39; 导致 Kubelet 启动失败分析过程总结</title>
      <link>/post/kubernetes-no-podsandbox-found/</link>
      <pubDate>Tue, 08 Dec 2020 03:38:37 +0000</pubDate>
      
      <guid>/post/kubernetes-no-podsandbox-found/</guid>
      <description>&lt;p&gt;某线上客户反应 Kubernetes 集群中一节点显示为 &amp;ldquo;NotReady&amp;rdquo; 状态，重启 Kubelet 后任然无法恢复。由于无法连接环境，只能拿到少量相关日志信息，因此尝试本地重现。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kubernetes RBAC - 证书认证</title>
      <link>/post/kubernetes-rbac-certificates/</link>
      <pubDate>Fri, 04 Dec 2020 00:37:34 +0000</pubDate>
      
      <guid>/post/kubernetes-rbac-certificates/</guid>
      <description>X509 客户证书 一般 Kubernetes 集群都会启用基于客户证书的用户认证模式。 API Server 通过 --client-ca-file=SOMEFILE 选项配置 CA 证书用于客户证书认证。如果提供的证书被验证通过，则 subject 中的公共名称（Common Name）就被作为请求的用户名。 通常可以使用两种方式签发：
通过 CertificateSigningRequest 资源类型允许客户申请签名 X.509 证书 使用外部证书服务颁发证书，如 openssl 通过 CSR API 签发证书步骤： 生成用户私钥： openssl genrsa -out user2.key 2048 使用私钥生成证书签名请求 CSR: openssl req -new -key user2.key -out user2.csr -subj &amp;#34;/CN=user2/O=group1/O=group2&amp;#34; 如果遇到错误信息 Can&#39;t load /home/ubuntu/.rnd into RNG 需先执行：</description>
    </item>
    
    <item>
      <title>CKA 实战 第二章 安装与升级</title>
      <link>/post/cka-in-action-chapter1-installation/</link>
      <pubDate>Thu, 19 Nov 2020 09:30:43 +0000</pubDate>
      
      <guid>/post/cka-in-action-chapter1-installation/</guid>
      <description>Kubernetes 有多种部署方式，学习环境可以选用 Minikube 或 Kind 等。但在 CKA 认证考试中会考察基于 Kubeadm 的部署方式， 操作系统为 Ubuntu。你可以使用云主机或者VirlualBox虚拟机环境安装 Ubuntu。这里我们推荐在线教学环境 KataKoda。 Kadakda 的课程中提供了交互式教学环境，我们既可以参考其实验步骤，也可独立使用其在线环境。
什么是 Kubeadm? Kubeadm 是 Kubernetes 集群快速安装部署工具，它解决了 Kubernetes 核心组件安装，TLS 加密配置，证书管理等问题，提供了开箱即用的安全特性。
Kubeadm 常用命令 kubeadm init 用于初始化 Kubernetes 控制面 kubeadm join 将工作节点加入集群或者添加其他控制面节点 kubeadm upgrade 用户升级 Kubernetes 集群 kubeadm reset 重置当前主机，恢复 kubeadm init 或 kubeadm join 的配置。 Kubernetes 组件 Kubernetes 集群由控制面与集群节点两部分组成， 节点上运行应用的工作负载 Pod，控制面负责集群中的工作节点与 Pod 的管理。</description>
    </item>
    
    <item>
      <title>Kubernetes Issue 归类指南</title>
      <link>/post/issue-triage/</link>
      <pubDate>Fri, 06 Nov 2020 08:42:33 +0000</pubDate>
      
      <guid>/post/issue-triage/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Issue 管理是软件工程中重要的一个环节。项目管理者可以通过 issue 对项目做持续的追踪，复审，把握整体的质量和进度。同时及时发现风险和问题。在开源软管理过程中，issue 的追踪变得更为棘手，来自全世界开发者的 issue 会源源不断的进入 issue 管理系统中。因此更需要一个高效的管理流程及工具。&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>基于 KubeSphere 的 Spring Could 微服务 CI/CD 实践</title>
      <link>/post/spring-cloud-on-kubeshpere/</link>
      <pubDate>Thu, 22 Oct 2020 02:06:46 +0000</pubDate>
      
      <guid>/post/spring-cloud-on-kubeshpere/</guid>
      <description>&lt;p&gt;本文以 Pig 为例介绍如何在 KubeSphere 上发布一个基于 Spring Cloud 微服务的 CI/CD 项目。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>基于Ubuntu18.04的云原生应用开发环境搭建 – KinD 搭建Kubernetes多节点集群</title>
      <link>/post/kind-setup/</link>
      <pubDate>Mon, 19 Oct 2020 01:13:57 +0000</pubDate>
      
      <guid>/post/kind-setup/</guid>
      <description>基于Ubuntu18.04的云原生应用开发环境搭建 &amp;ndash; KinD 搭建Kubernetes多节点集群 KinD是Kubernetes in Docker的简称，它的主要目标是用于测试Kubernetes本身。也可以用于搭建本地Kubernetes开发环境，开发云原生应用。KinD可以运行在Windows，Macos和linux中。本文以Ubuntu为例，介绍kind的常用命令以及配置。
前提条件 已安装Ubuntu18.04桌面版 已安装Docker 下载最新版KinD 当前kind版本为v0.9.0,可以使用以下命令下载并安装
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.9.0/kind-linux-amd64 chmod +x ./kind sudo mv ./kind /usr/local/bin/ Kind使用 创建集群 创建Kubernetes集群最简单的方式就是使用kind create cluster命令。执行后3-5分钟即可启动一个K8S集群。同时kind会更新${HOME}/.kube/config下的kubeconfig。默认集群名字为kind，也可通过&amp;ndash;name 指定名称。
常用命令 查看已创建的集群 kind get clusters 删除集群 kind delete cluster --name your-cluster 高级选项 多节点集群 kind最重要的功能之一是创建多节点集群，为了创建多个node，我们需要先创建一个yaml配置文件。如：
# three node (two workers) cluster config kind: Cluster apiVersion: kind.</description>
    </item>
    
    <item>
      <title>基于Ubuntu18.04的云原生应用开发环境搭建VSCode&amp;Golang</title>
      <link>/post/vscode-golang/</link>
      <pubDate>Tue, 22 Sep 2020 01:42:38 +0000</pubDate>
      
      <guid>/post/vscode-golang/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
